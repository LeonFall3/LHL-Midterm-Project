{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- The os module has a perfect method to list files in a directory.\n",
    "- Pandas json normalize could work here but is not necessary to convert the JSON data to a dataframe.\n",
    "- You may need a nested for-loop to access each sale!\n",
    "- We've put a lot of time into creating the structure of this repository, and it's a good example for future projects.  In the file functions_variables.py, there is an example function that you can import and use.  If you have any variables, functions or classes that you want to make, they can be put in the functions_variables.py file and imported into a notebook.  Note that only .py files can be imported into a notebook. If you want to import everything from a .py file, you can use the following:\n",
    "```python\n",
    "from functions_variables import *\n",
    "```\n",
    "If you just import functions_variables, then each object from the file will need to be prepended with \"functions_variables\"\\\n",
    "Using this .py file will keep your notebooks very organized and make it easier to reuse code between notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "import sys\n",
    "import seaborn as sns\n",
    "sys.path.append(r'notebooks\\python_scripts')\n",
    "from API_calls import *\n",
    "from data_importing_cleaning import *\n",
    "from sub_df_creation import *\n",
    "\n",
    "load_dotenv()\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "api_key=os.getenv('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Importing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please see `data_importing_cleaning.py` for the full data import function. Below is an overview of the function.\n",
    "\n",
    "Check all files in 'data/' that end with `.json` and normalize them.\n",
    "Explode tags and encode them. Drop 'tags' column and join new tag columns.\n",
    "Convert dtypes.\n",
    "Drop all 'property_id' dupes, keeping only the first one.\n",
    "Rename columns.\n",
    "Drop all columns that aren't needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseball</th>\n",
       "      <th>basement</th>\n",
       "      <th>basketball</th>\n",
       "      <th>basketball_court</th>\n",
       "      <th>beach</th>\n",
       "      <th>beautiful_backyard</th>\n",
       "      <th>big_bathroom</th>\n",
       "      <th>big_lot</th>\n",
       "      <th>big_yard</th>\n",
       "      <th>boat_dock</th>\n",
       "      <th>...</th>\n",
       "      <th>sqft</th>\n",
       "      <th>baths</th>\n",
       "      <th>garage</th>\n",
       "      <th>beds</th>\n",
       "      <th>type</th>\n",
       "      <th>state</th>\n",
       "      <th>coords_lon</th>\n",
       "      <th>coords_lat</th>\n",
       "      <th>city</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9074430767</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1821.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>single_family</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>-134.59372</td>\n",
       "      <td>58.36395</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>9453 Herbert Pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9424983842</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1925.534536</td>\n",
       "      <td>2.127708</td>\n",
       "      <td>1.928352</td>\n",
       "      <td>3.207043</td>\n",
       "      <td>single_family</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>8477 Thunder Mountain Rd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9479068516</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1925.534536</td>\n",
       "      <td>2.127708</td>\n",
       "      <td>1.928352</td>\n",
       "      <td>3.207043</td>\n",
       "      <td>single_family</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>4515 Glacier Hwy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9879331943</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1925.534536</td>\n",
       "      <td>2.127708</td>\n",
       "      <td>1.928352</td>\n",
       "      <td>3.207043</td>\n",
       "      <td>single_family</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>17850 Point Stephens Rd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9521639574</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1925.534536</td>\n",
       "      <td>2.127708</td>\n",
       "      <td>1.928352</td>\n",
       "      <td>3.207043</td>\n",
       "      <td>single_family</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>9951 Stephen Richards Memorial Dr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 169 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             baseball  basement  basketball  basketball_court  beach  \\\n",
       "property_id                                                            \n",
       "9074430767        0.0       1.0         0.0               0.0    0.0   \n",
       "9424983842        0.0       0.0         0.0               0.0    0.0   \n",
       "9479068516        0.0       0.0         0.0               0.0    0.0   \n",
       "9879331943        0.0       0.0         0.0               0.0    0.0   \n",
       "9521639574        0.0       0.0         0.0               0.0    0.0   \n",
       "\n",
       "             beautiful_backyard  big_bathroom  big_lot  big_yard  boat_dock  \\\n",
       "property_id                                                                   \n",
       "9074430767                  0.0           0.0      0.0       1.0        0.0   \n",
       "9424983842                  0.0           0.0      0.0       0.0        0.0   \n",
       "9479068516                  0.0           0.0      0.0       0.0        0.0   \n",
       "9879331943                  0.0           0.0      0.0       0.0        0.0   \n",
       "9521639574                  0.0           0.0      0.0       0.0        0.0   \n",
       "\n",
       "             ...         sqft     baths    garage      beds           type  \\\n",
       "property_id  ...                                                             \n",
       "9074430767   ...  1821.000000  2.000000  1.000000  3.000000  single_family   \n",
       "9424983842   ...  1925.534536  2.127708  1.928352  3.207043  single_family   \n",
       "9479068516   ...  1925.534536  2.127708  1.928352  3.207043  single_family   \n",
       "9879331943   ...  1925.534536  2.127708  1.928352  3.207043  single_family   \n",
       "9521639574   ...  1925.534536  2.127708  1.928352  3.207043  single_family   \n",
       "\n",
       "              state  coords_lon  coords_lat    city  \\\n",
       "property_id                                           \n",
       "9074430767   Alaska  -134.59372    58.36395  Juneau   \n",
       "9424983842   Alaska        <NA>        <NA>  Juneau   \n",
       "9479068516   Alaska        <NA>        <NA>  Juneau   \n",
       "9879331943   Alaska        <NA>        <NA>  Juneau   \n",
       "9521639574   Alaska        <NA>        <NA>  Juneau   \n",
       "\n",
       "                                       address  \n",
       "property_id                                     \n",
       "9074430767                     9453 Herbert Pl  \n",
       "9424983842            8477 Thunder Mountain Rd  \n",
       "9479068516                    4515 Glacier Hwy  \n",
       "9879331943             17850 Point Stephens Rd  \n",
       "9521639574   9951 Stephen Richards Memorial Dr  \n",
       "\n",
       "[5 rows x 169 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import and pickle raw df\n",
    "# df = JSON_import(r'data/')\n",
    "# df.to_pickle('data/!raw_df.pkl')\n",
    "\n",
    "# Cleaning data\n",
    "# df= cleaning_data(df)\n",
    "# df.to_pickle('data/!cleaned_df.pkl')\n",
    "# df.to_csv('df.csv')\n",
    "# #dealing with missing data\n",
    "# df = missing_data(df)\n",
    "# df.to_pickle('data/!complete_df.pkl')\n",
    "\n",
    "# load pickled df\n",
    "df= pd.read_pickle('data/!complete_df.pkl')\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, ensure that you have all sales in a dataframe.\n",
    "- Take a quick look at your data (i.e. `.info()`, `.describe()`) - what do you see?\n",
    "- Is each cell one value, or do some cells have lists?\n",
    "- What are the data types of each column?\n",
    "- Some sales may not actually include the sale price (target).  These rows should be dropped.\n",
    "- There are a lot of NA/None values.  Should these be dropped or replaced with something?\n",
    "    - You can drop rows or use various methods to fills NA's - use your best judgement for each column \n",
    "    - i.e. for some columns (like Garage), NA probably just means no Garage, so 0\n",
    "- Drop columns that aren't needed\n",
    "    - Don't keep the list price because it will be too close to the sale price. Assume we want to predict the price of houses not yet listed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1700 entries, 9074430767 to 22975\n",
      "Columns: 169 entries, baseball to address\n",
      "dtypes: Float64(2), float64(162), object(1), string(4)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseball</th>\n",
       "      <th>basement</th>\n",
       "      <th>basketball</th>\n",
       "      <th>basketball_court</th>\n",
       "      <th>beach</th>\n",
       "      <th>beautiful_backyard</th>\n",
       "      <th>big_bathroom</th>\n",
       "      <th>big_lot</th>\n",
       "      <th>big_yard</th>\n",
       "      <th>boat_dock</th>\n",
       "      <th>...</th>\n",
       "      <th>wrap_around_porch</th>\n",
       "      <th>sold_price</th>\n",
       "      <th>baths_full</th>\n",
       "      <th>baths_half</th>\n",
       "      <th>sqft</th>\n",
       "      <th>baths</th>\n",
       "      <th>garage</th>\n",
       "      <th>beds</th>\n",
       "      <th>coords_lon</th>\n",
       "      <th>coords_lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1.700000e+03</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>1665.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.001767</td>\n",
       "      <td>0.429892</td>\n",
       "      <td>0.008833</td>\n",
       "      <td>0.008833</td>\n",
       "      <td>0.005890</td>\n",
       "      <td>0.006478</td>\n",
       "      <td>0.011778</td>\n",
       "      <td>0.117797</td>\n",
       "      <td>0.074200</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002944</td>\n",
       "      <td>4.293362e+05</td>\n",
       "      <td>1.886020</td>\n",
       "      <td>1.104000</td>\n",
       "      <td>1925.377792</td>\n",
       "      <td>2.241603</td>\n",
       "      <td>1.927722</td>\n",
       "      <td>3.206577</td>\n",
       "      <td>-92.261607</td>\n",
       "      <td>39.023855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.041984</td>\n",
       "      <td>0.494919</td>\n",
       "      <td>0.093545</td>\n",
       "      <td>0.093545</td>\n",
       "      <td>0.076493</td>\n",
       "      <td>0.080203</td>\n",
       "      <td>0.107856</td>\n",
       "      <td>0.322259</td>\n",
       "      <td>0.262027</td>\n",
       "      <td>0.024254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054169</td>\n",
       "      <td>7.996650e+05</td>\n",
       "      <td>0.832723</td>\n",
       "      <td>0.223135</td>\n",
       "      <td>1249.773573</td>\n",
       "      <td>1.076631</td>\n",
       "      <td>0.668749</td>\n",
       "      <td>1.251666</td>\n",
       "      <td>16.094417</td>\n",
       "      <td>4.421147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.500000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-157.810583</td>\n",
       "      <td>21.277707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.250000e+05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1287.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.928352</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-104.973819</td>\n",
       "      <td>35.685564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.750000e+05</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.104000</td>\n",
       "      <td>1697.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.928352</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-89.338655</td>\n",
       "      <td>39.690714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.300000e+05</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.104000</td>\n",
       "      <td>2204.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-78.567521</td>\n",
       "      <td>41.838319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.706500e+07</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>32106.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>-71.006343</td>\n",
       "      <td>58.396178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          baseball     basement   basketball  basketball_court        beach  \\\n",
       "count  1700.000000  1700.000000  1700.000000       1700.000000  1700.000000   \n",
       "mean      0.001767     0.429892     0.008833          0.008833     0.005890   \n",
       "std       0.041984     0.494919     0.093545          0.093545     0.076493   \n",
       "min       0.000000     0.000000     0.000000          0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000          0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000          0.000000     0.000000   \n",
       "75%       0.000000     1.000000     0.000000          0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000          1.000000     1.000000   \n",
       "\n",
       "       beautiful_backyard  big_bathroom      big_lot     big_yard  \\\n",
       "count         1700.000000   1700.000000  1700.000000  1700.000000   \n",
       "mean             0.006478      0.011778     0.117797     0.074200   \n",
       "std              0.080203      0.107856     0.322259     0.262027   \n",
       "min              0.000000      0.000000     0.000000     0.000000   \n",
       "25%              0.000000      0.000000     0.000000     0.000000   \n",
       "50%              0.000000      0.000000     0.000000     0.000000   \n",
       "75%              0.000000      0.000000     0.000000     0.000000   \n",
       "max              1.000000      1.000000     1.000000     1.000000   \n",
       "\n",
       "         boat_dock  ...  wrap_around_porch    sold_price   baths_full  \\\n",
       "count  1700.000000  ...        1700.000000  1.700000e+03  1700.000000   \n",
       "mean      0.000589  ...           0.002944  4.293362e+05     1.886020   \n",
       "std       0.024254  ...           0.054169  7.996650e+05     0.832723   \n",
       "min       0.000000  ...           0.000000  2.500000e+03     1.000000   \n",
       "25%       0.000000  ...           0.000000  2.250000e+05     1.000000   \n",
       "50%       0.000000  ...           0.000000  3.750000e+05     2.000000   \n",
       "75%       0.000000  ...           0.000000  4.300000e+05     2.000000   \n",
       "max       1.000000  ...           1.000000  2.706500e+07     8.000000   \n",
       "\n",
       "        baths_half          sqft        baths       garage         beds  \\\n",
       "count  1700.000000   1700.000000  1700.000000  1700.000000  1700.000000   \n",
       "mean      1.104000   1925.377792     2.241603     1.927722     3.206577   \n",
       "std       0.223135   1249.773573     1.076631     0.668749     1.251666   \n",
       "min       1.000000    120.000000     0.000000     1.000000     0.000000   \n",
       "25%       1.000000   1287.000000     2.000000     1.928352     3.000000   \n",
       "50%       1.104000   1697.500000     2.000000     1.928352     3.000000   \n",
       "75%       1.104000   2204.000000     3.000000     2.000000     4.000000   \n",
       "max       5.000000  32106.000000     9.000000    11.000000    12.000000   \n",
       "\n",
       "       coords_lon  coords_lat  \n",
       "count      1665.0      1665.0  \n",
       "mean   -92.261607   39.023855  \n",
       "std     16.094417    4.421147  \n",
       "min   -157.810583   21.277707  \n",
       "25%   -104.973819   35.685564  \n",
       "50%    -89.338655   39.690714  \n",
       "75%    -78.567521   41.838319  \n",
       "max    -71.006343   58.396178  \n",
       "\n",
       "[8 rows x 164 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please see `data_importing_cleaning.py` for the full data cleaning function. Below is an overview of the function.\n",
    "\n",
    "WILL UPDATE ONCE LANDON IS NONE HIS PASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please see `data_importing_cleaning.py` for the full missing data function. Below is an overview of the function.\n",
    "\n",
    "Input some missing data that are easily findable.\n",
    "Drop all rows that are missing address and coordinates.\n",
    "\n",
    "\n",
    "WILL UPDATE ONCE LANDON IS NONE HIS PASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the fact that with tags, there are a lot of categorical variables.\n",
    "- How many columns would we have if we OHE tags, city and state?\n",
    "- Perhaps we can get rid of tags that have a low frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE categorical variables/ tags here\n",
    "# tags will have to be done manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sales will vary drastically between cities and states.  Is there a way to keep information about which city it is without OHE?\n",
    "- Could we label encode or ordinal encode?  Yes, but this may have undesirable effects, giving nominal data ordinal values.\n",
    "- What we can do is use our training data to encode the mean sale price by city as a feature (a.k.a. Target Encoding)\n",
    "    - We can do this as long as we ONLY use the training data - we're using the available data to give us a 'starting guess' of the price for each city, without needing to encode city explicitly\n",
    "- If you replace cities or states with numerical values (like the mean price), make sure that the data is split so that we don't leak data into the training selection. This is a great time to train test split. Compute on the training data, and join these values to the test data\n",
    "- Note that you *may* have cities in the test set that are not in the training set. You don't want these to be NA, so maybe you can fill them with the overall mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform train test split here\n",
    "# do something with state and city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Data - STRETCH\n",
    "\n",
    "> This doesn't need to be part of your Minimum Viable Product (MVP). We recommend you write a functional, basic pipeline first, then circle back and join new data if you have time\n",
    "\n",
    "> If you do this, try to write your downstream steps in a way it will still work on a dataframe with different features!\n",
    "\n",
    "- You're not limited to just using the data provided to you. Think/ do some research about other features that might be useful to predict housing prices. \n",
    "- Can you import and join this data? Make sure you do any necessary preprocessing and make sure it is joined correctly.\n",
    "- Example suggestion: could mortgage interest rates in the year of the listing affect the price? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'property_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mb:\\LHL\\python\\.conda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'property_id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# import, join and preprocess new data here\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m busstops\u001b[38;5;241m=\u001b[39m \u001b[43mbus_query_by_lat_long\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Convert Series to DataFrame and rename columns\u001b[39;00m\n\u001b[0;32m      4\u001b[0m busstops_df \u001b[38;5;241m=\u001b[39m busstops\u001b[38;5;241m.\u001b[39mrename_axis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproperty_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbusstops\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mb:\\LHL\\LHL-Midterm-Project\\notebooks\\python_scripts\\API_calls.py:27\u001b[0m, in \u001b[0;36mbus_query_by_lat_long\u001b[1;34m(df, api_key, radius, place_type, batch_size, delay)\u001b[0m\n\u001b[0;32m     25\u001b[0m latitude \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoords_lat\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     26\u001b[0m longitude \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoords_lon\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 27\u001b[0m property_id \u001b[38;5;241m=\u001b[39m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproperty_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Construct the API URL\u001b[39;00m\n\u001b[0;32m     29\u001b[0m url \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://maps.googleapis.com/maps/api/place/nearbysearch/json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m?location=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlatitude\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlongitude\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m&key=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapi_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     35\u001b[0m )\n",
      "File \u001b[1;32mb:\\LHL\\python\\.conda\\Lib\\site-packages\\pandas\\core\\series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32mb:\\LHL\\python\\.conda\\Lib\\site-packages\\pandas\\core\\series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mb:\\LHL\\python\\.conda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'property_id'"
     ]
    }
   ],
   "source": [
    "# import, join and preprocess new data here\n",
    "busstops= bus_query_by_lat_long(df, api_key)\n",
    "# Convert Series to DataFrame and rename columns\n",
    "busstops_df = busstops.rename_axis('property_id').reset_index(name='busstops')\n",
    "# Merge results_df into notags_df based on 'property_id'\n",
    "df = df.merge(\n",
    "    busstops_df[['property_id', 'busstops']],\n",
    "    on='property_id',\n",
    "    how='left'\n",
    ")\n",
    "df['busstops'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA/ Visualization\n",
    "\n",
    "Remember all of the EDA that you've been learning about?  Now is a perfect time for it!\n",
    "- Look at distributions of numerical variables to see the shape of the data and detect outliers.    \n",
    "    - Consider transforming very skewed variables\n",
    "- Scatterplots of a numerical variable and the target go a long way to show correlations.\n",
    "- A heatmap will help detect highly correlated features, and we don't want these.\n",
    "    - You may have too many features to do this, in which case you can simply compute the most correlated feature-pairs and list them\n",
    "- Is there any overlap in any of the features? (redundant information, like number of this or that room...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap Corelation Check on Num Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A given column is not a column of the dataframe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mb:\\LHL\\python\\.conda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'busstops'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mb:\\LHL\\python\\.conda\\Lib\\site-packages\\sklearn\\utils\\_indexing.py:361\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[1;34m(X, key)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[1;32m--> 361\u001b[0m     col_idx \u001b[38;5;241m=\u001b[39m \u001b[43mall_columns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col_idx, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n",
      "File \u001b[1;32mb:\\LHL\\python\\.conda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'busstops'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 26\u001b[0m\n\u001b[0;32m     21\u001b[0m preprocess \u001b[38;5;241m=\u001b[39m ColumnTransformer(transformers\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     22\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_vals\u001b[39m\u001b[38;5;124m'\u001b[39m, num_pipeline, num_cols_base),\n\u001b[0;32m     23\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat_vals\u001b[39m\u001b[38;5;124m'\u001b[39m, cat_pipeline, cat_cols_base)\n\u001b[0;32m     24\u001b[0m ]) \n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m#transform the data\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m x_transformed \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m cat_encoded_cols \u001b[38;5;241m=\u001b[39m preprocess\u001b[38;5;241m.\u001b[39mnamed_transformers_[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcat_vals\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mohe\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget_feature_names_out(cat_cols_base)\n\u001b[0;32m     31\u001b[0m all_columns \u001b[38;5;241m=\u001b[39m num_cols_base \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(cat_encoded_cols)\n",
      "File \u001b[1;32mb:\\LHL\\python\\.conda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    319\u001b[0m         )\n",
      "File \u001b[1;32mb:\\LHL\\python\\.conda\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mb:\\LHL\\python\\.conda\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:968\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    965\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_transformers()\n\u001b[0;32m    966\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[1;32m--> 968\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_column_callables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_remainder(X)\n\u001b[0;32m    971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _routing_enabled():\n",
      "File \u001b[1;32mb:\\LHL\\python\\.conda\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:536\u001b[0m, in \u001b[0;36mColumnTransformer._validate_column_callables\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    534\u001b[0m         columns \u001b[38;5;241m=\u001b[39m columns(X)\n\u001b[0;32m    535\u001b[0m     all_columns\u001b[38;5;241m.\u001b[39mappend(columns)\n\u001b[1;32m--> 536\u001b[0m     transformer_to_input_indices[name] \u001b[38;5;241m=\u001b[39m \u001b[43m_get_column_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_columns \u001b[38;5;241m=\u001b[39m all_columns\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer_to_input_indices \u001b[38;5;241m=\u001b[39m transformer_to_input_indices\n",
      "File \u001b[1;32mb:\\LHL\\python\\.conda\\Lib\\site-packages\\sklearn\\utils\\_indexing.py:369\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[1;34m(X, key)\u001b[0m\n\u001b[0;32m    366\u001b[0m         column_indices\u001b[38;5;241m.\u001b[39mappend(col_idx)\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 369\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA given column is not a column of the dataframe\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m column_indices\n",
      "\u001b[1;31mValueError\u001b[0m: A given column is not a column of the dataframe"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import matplotlib as plt\n",
    "#set the paramaters \n",
    "\n",
    "num_cols_base = ['sold_price', 'beds', 'baths', 'busstops', 'sqft']\n",
    "cat_cols_base = ['type']\n",
    "\n",
    "#Build the pipelines\n",
    "num_pipeline = Pipeline([(\"impude\", SimpleImputer()), (\"scale\", StandardScaler())])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine with ColumnTransformer\n",
    "preprocess = ColumnTransformer(transformers=[\n",
    "    ('num_vals', num_pipeline, num_cols_base),\n",
    "    ('cat_vals', cat_pipeline, cat_cols_base)\n",
    "]) \n",
    "#transform the data\n",
    "x_transformed = preprocess.fit_transform(df)\n",
    "\n",
    "\n",
    "cat_encoded_cols = preprocess.named_transformers_[\"cat_vals\"][\"ohe\"].get_feature_names_out(cat_cols_base)\n",
    "\n",
    "all_columns = num_cols_base + list(cat_encoded_cols)\n",
    "\n",
    "transformed_df = pd.DataFrame(x_transformed, columns=all_columns)\n",
    "corr_matrix = transformed_df.corr()\n",
    "#plot the heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = df[num_cols_base]\n",
    "\n",
    "for col in num_df:\n",
    "    if col != 'sold_price':\n",
    "        # Plot distribution\n",
    "        sns.histplot(df[col], kde=True)\n",
    "        plt.title(f'Distribution of {col}')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling and Finishing Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now is a great time to scale the data and save it once it's preprocessed.\n",
    "- You can save it in your data folder, but you may want to make a new `processed/` subfolder to keep it organized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property_id</th>\n",
       "      <th>baseball</th>\n",
       "      <th>basement</th>\n",
       "      <th>basketball</th>\n",
       "      <th>basketball_court</th>\n",
       "      <th>beach</th>\n",
       "      <th>beautiful_backyard</th>\n",
       "      <th>big_bathroom</th>\n",
       "      <th>big_lot</th>\n",
       "      <th>big_yard</th>\n",
       "      <th>...</th>\n",
       "      <th>beds</th>\n",
       "      <th>type</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>state</th>\n",
       "      <th>coords_lon</th>\n",
       "      <th>coords_lat</th>\n",
       "      <th>city</th>\n",
       "      <th>address</th>\n",
       "      <th>street_view_url</th>\n",
       "      <th>county</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9074430767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>single_family</td>\n",
       "      <td>99801</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>-134.593720</td>\n",
       "      <td>58.363950</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>9453 Herbert Pl</td>\n",
       "      <td>https://maps.googleapis.com/maps/api/streetvie...</td>\n",
       "      <td>Juneau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9424983842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.207043</td>\n",
       "      <td>single_family</td>\n",
       "      <td>99801</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>-92.285176</td>\n",
       "      <td>38.996694</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>8477 Thunder Mountain Rd</td>\n",
       "      <td>https://maps.googleapis.com/maps/api/streetvie...</td>\n",
       "      <td>Juneau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9479068516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.207043</td>\n",
       "      <td>single_family</td>\n",
       "      <td>99801</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>-92.285176</td>\n",
       "      <td>38.996694</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>4515 Glacier Hwy</td>\n",
       "      <td>https://maps.googleapis.com/maps/api/streetvie...</td>\n",
       "      <td>Juneau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9879331943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.207043</td>\n",
       "      <td>single_family</td>\n",
       "      <td>99801</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>-92.285176</td>\n",
       "      <td>38.996694</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>17850 Point Stephens Rd</td>\n",
       "      <td>https://maps.googleapis.com/maps/api/streetvie...</td>\n",
       "      <td>Juneau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9521639574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.207043</td>\n",
       "      <td>single_family</td>\n",
       "      <td>99801</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>-92.285176</td>\n",
       "      <td>38.996694</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>9951 Stephen Richards Memorial Dr</td>\n",
       "      <td>https://maps.googleapis.com/maps/api/streetvie...</td>\n",
       "      <td>Juneau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38363</th>\n",
       "      <td>4542127284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>single_family</td>\n",
       "      <td>25314</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>-81.644994</td>\n",
       "      <td>38.341576</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>1008 Oakmont Rd</td>\n",
       "      <td>https://maps.googleapis.com/maps/api/streetvie...</td>\n",
       "      <td>Kanawha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38368</th>\n",
       "      <td>3895826397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>single_family</td>\n",
       "      <td>25387</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>-81.661662</td>\n",
       "      <td>38.377371</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>1041 Temple St</td>\n",
       "      <td>https://maps.googleapis.com/maps/api/streetvie...</td>\n",
       "      <td>Kanawha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38373</th>\n",
       "      <td>4941005485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>single_family</td>\n",
       "      <td>25314</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>-81.659885</td>\n",
       "      <td>38.338617</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>238 Oakwood Rd</td>\n",
       "      <td>https://maps.googleapis.com/maps/api/streetvie...</td>\n",
       "      <td>Kanawha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38378</th>\n",
       "      <td>4306867390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>single_family</td>\n",
       "      <td>25302</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>-81.644214</td>\n",
       "      <td>38.363038</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>408 Lee St W</td>\n",
       "      <td>https://maps.googleapis.com/maps/api/streetvie...</td>\n",
       "      <td>Kanawha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38582</th>\n",
       "      <td>3616897910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>single_family</td>\n",
       "      <td>25302</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>-81.640806</td>\n",
       "      <td>38.377955</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>625 Wood Rd</td>\n",
       "      <td>https://maps.googleapis.com/maps/api/streetvie...</td>\n",
       "      <td>Kanawha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1793 rows × 177 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      property_id  baseball  basement  basketball  basketball_court  beach  \\\n",
       "0      9074430767       0.0       1.0         0.0               0.0    0.0   \n",
       "1      9424983842       0.0       0.0         0.0               0.0    0.0   \n",
       "3      9479068516       0.0       0.0         0.0               0.0    0.0   \n",
       "6      9879331943       0.0       0.0         0.0               0.0    0.0   \n",
       "10     9521639574       0.0       0.0         0.0               0.0    0.0   \n",
       "...           ...       ...       ...         ...               ...    ...   \n",
       "38363  4542127284       0.0       1.0         0.0               0.0    0.0   \n",
       "38368  3895826397       0.0       1.0         0.0               0.0    0.0   \n",
       "38373  4941005485       0.0       1.0         0.0               0.0    0.0   \n",
       "38378  4306867390       0.0       0.0         0.0               0.0    0.0   \n",
       "38582  3616897910       0.0       1.0         0.0               0.0    0.0   \n",
       "\n",
       "       beautiful_backyard  big_bathroom  big_lot  big_yard  ...      beds  \\\n",
       "0                     0.0           0.0      0.0       1.0  ...  3.000000   \n",
       "1                     0.0           0.0      0.0       0.0  ...  3.207043   \n",
       "3                     0.0           0.0      0.0       0.0  ...  3.207043   \n",
       "6                     0.0           0.0      0.0       0.0  ...  3.207043   \n",
       "10                    0.0           0.0      0.0       0.0  ...  3.207043   \n",
       "...                   ...           ...      ...       ...  ...       ...   \n",
       "38363                 0.0           0.0      1.0       0.0  ...  3.000000   \n",
       "38368                 0.0           0.0      1.0       0.0  ...  3.000000   \n",
       "38373                 0.0           0.0      1.0       0.0  ...  3.000000   \n",
       "38378                 0.0           0.0      0.0       0.0  ...  0.000000   \n",
       "38582                 0.0           0.0      0.0       0.0  ...  3.000000   \n",
       "\n",
       "                type  zip_code          state  coords_lon  coords_lat  \\\n",
       "0      single_family     99801         Alaska -134.593720   58.363950   \n",
       "1      single_family     99801         Alaska  -92.285176   38.996694   \n",
       "3      single_family     99801         Alaska  -92.285176   38.996694   \n",
       "6      single_family     99801         Alaska  -92.285176   38.996694   \n",
       "10     single_family     99801         Alaska  -92.285176   38.996694   \n",
       "...              ...       ...            ...         ...         ...   \n",
       "38363  single_family     25314  West Virginia  -81.644994   38.341576   \n",
       "38368  single_family     25387  West Virginia  -81.661662   38.377371   \n",
       "38373  single_family     25314  West Virginia  -81.659885   38.338617   \n",
       "38378  single_family     25302  West Virginia  -81.644214   38.363038   \n",
       "38582  single_family     25302  West Virginia  -81.640806   38.377955   \n",
       "\n",
       "             city                            address  \\\n",
       "0          Juneau                    9453 Herbert Pl   \n",
       "1          Juneau           8477 Thunder Mountain Rd   \n",
       "3          Juneau                   4515 Glacier Hwy   \n",
       "6          Juneau            17850 Point Stephens Rd   \n",
       "10         Juneau  9951 Stephen Richards Memorial Dr   \n",
       "...           ...                                ...   \n",
       "38363  Charleston                    1008 Oakmont Rd   \n",
       "38368  Charleston                     1041 Temple St   \n",
       "38373  Charleston                     238 Oakwood Rd   \n",
       "38378  Charleston                       408 Lee St W   \n",
       "38582  Charleston                        625 Wood Rd   \n",
       "\n",
       "                                         street_view_url   county  \n",
       "0      https://maps.googleapis.com/maps/api/streetvie...   Juneau  \n",
       "1      https://maps.googleapis.com/maps/api/streetvie...   Juneau  \n",
       "3      https://maps.googleapis.com/maps/api/streetvie...   Juneau  \n",
       "6      https://maps.googleapis.com/maps/api/streetvie...   Juneau  \n",
       "10     https://maps.googleapis.com/maps/api/streetvie...   Juneau  \n",
       "...                                                  ...      ...  \n",
       "38363  https://maps.googleapis.com/maps/api/streetvie...  Kanawha  \n",
       "38368  https://maps.googleapis.com/maps/api/streetvie...  Kanawha  \n",
       "38373  https://maps.googleapis.com/maps/api/streetvie...  Kanawha  \n",
       "38378  https://maps.googleapis.com/maps/api/streetvie...  Kanawha  \n",
       "38582  https://maps.googleapis.com/maps/api/streetvie...  Kanawha  \n",
       "\n",
       "[1793 rows x 177 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
